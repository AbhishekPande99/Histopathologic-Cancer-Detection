{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train_labels.csv', 'train', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n",
    "    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n",
    "    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "from keras.layers.pooling import _GlobalPooling1D\n",
    "from keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras.applications.nasnet import NASNetMobile, NASNetLarge, preprocess_input, decode_predictions\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "print(os.listdir(\"../input\"))\n",
    "import sys\n",
    "# Add directory holding utility functions to path to allow importing utility functions\n",
    "sys.path.append('/kaggle/input/python-utility-code-for-deep-learning-exercises/utils')\n",
    "#from decode_predictions import decode_predictions\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../input/train_labels.csv\")\n",
    "id_label_map = {k:v for k,v in zip(df_train.id.values, df_train.label.values)}\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2b408587bcf2a06aab210c720cbc5e0fc0dc24d1"
   },
   "outputs": [],
   "source": [
    "def get_id_from_file_path(file_path):\n",
    "    return file_path.split(os.path.sep)[-1].replace('.tif', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f90dc2144e8dffc3ffe1f48d6c3c0a5de97fec26"
   },
   "outputs": [],
   "source": [
    "labeled_files = glob('../input/train/*.tif')\n",
    "test_files = glob('../input/test/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "d2e2423c840e58856a27a07b342b91a6d984f6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_files size : 220025\n",
      "test_files size : 57458\n"
     ]
    }
   ],
   "source": [
    "print(\"labeled_files size :\", len(labeled_files))\n",
    "print(\"test_files size :\", len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "9e3427abaffe75077ff7394605fbdc090a68da35"
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(labeled_files, test_size=0.1, random_state=101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "69067d8a38e353d42f6ad1743c8ac77bc4fee50e"
   },
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "def get_seq():\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "            iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
    "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
    "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            )),\n",
    "            # execute 0 to 5 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 5),\n",
    "                [\n",
    "                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                    iaa.OneOf([\n",
    "                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
    "                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                    ]),\n",
    "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
    "                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                    # search either for all edges or for directed edges,\n",
    "                    # blend the result with the original image using a blobby mask\n",
    "                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                    ])),\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
    "                    ]),\n",
    "                    iaa.Invert(0.01, per_channel=True), # invert color channels\n",
    "                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
    "                    # either change the brightness of the whole image (sometimes\n",
    "                    # per channel) or change the brightness of subareas\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                        iaa.FrequencyNoiseAlpha(\n",
    "                            exponent=(-1, 0),\n",
    "                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
    "                            second=iaa.ContrastNormalization((0.9, 1.1))\n",
    "                        )\n",
    "                    ]),\n",
    "                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                ],\n",
    "                random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return seq\n",
    "\n",
    "def data_gen(list_files, id_label_map, batch_size, augment=False):\n",
    "    seq = get_seq()\n",
    "    while True:\n",
    "        shuffle(list_files)\n",
    "        for batch in chunker(list_files, batch_size):\n",
    "            X = [cv2.imread(x) for x in batch]\n",
    "            Y = [id_label_map[get_id_from_file_path(x)] for x in batch]\n",
    "            if augment:\n",
    "                X = seq.augment_images(X)\n",
    "            X = [preprocess_input(x) for x in X]\n",
    "                \n",
    "            yield np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "24122973bed183f28b1fc8f97e8767069eef92f3"
   },
   "outputs": [],
   "source": [
    "def get_model_classif_nasnet():\n",
    "    inputs = Input((96, 96, 3))\n",
    "    base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))#, weights=None\n",
    "    x = base_model(inputs)\n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.55)(out)\n",
    "    out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizer=Adam(0.00004), loss=binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6de5f6a6778a72dbe8b85e285596c931177cc31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5\n",
      "19996672/19993432 [==============================] - 0s 0us/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  multiple             4269716     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9504)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 11616)        0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 11616)        0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            11617       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,281,333\n",
      "Trainable params: 4,244,595\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model_classif_nasnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "fb94bccb204bc70c25908224d6e74f8441f303a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3094/3094 [==============================] - 1834s 593ms/step - loss: 0.5042 - acc: 0.7614 - val_loss: 0.3207 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86534, saving model to model.h5\n",
      "Epoch 2/2\n",
      "3094/3094 [==============================] - 1744s 564ms/step - loss: 0.3623 - acc: 0.8386 - val_loss: 0.2622 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86534 to 0.89576, saving model to model.h5\n",
      "Epoch 1/6\n",
      " 261/3094 [=>............................] - ETA: 26:16 - loss: 0.3303 - acc: 0.8576"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "h5_path = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    data_gen(train, id_label_map, batch_size, augment=True),\n",
    "    validation_data=data_gen(val, id_label_map, batch_size),\n",
    "    epochs=2, verbose=1,\n",
    "    callbacks=[checkpoint],\n",
    "    steps_per_epoch=len(train) // batch_size,\n",
    "    validation_steps=len(val) // batch_size)\n",
    "batch_size=64\n",
    "history = model.fit_generator(\n",
    "    data_gen(train, id_label_map, batch_size, augment=True),\n",
    "    validation_data=data_gen(val, id_label_map, batch_size),\n",
    "    epochs=6, verbose=1,\n",
    "    callbacks=[checkpoint],\n",
    "    steps_per_epoch=len(train) // batch_size,\n",
    "    validation_steps=len(val) // batch_size)\n",
    "\n",
    "model.load_weights(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2d0756b771c5d19fd2eff6f2d76de2d9fa1dc24f"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "dccc4374c379874332e45916dd37852638c596a6"
   },
   "outputs": [],
   "source": [
    "for batch in chunker(test_files, batch_size):\n",
    "    X = [preprocess_input(cv2.imread(x)) for x in batch]\n",
    "    ids_batch = [get_id_from_file_path(x) for x in batch]\n",
    "    X = np.array(X)\n",
    "    preds_batch = ((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n",
    "    preds += preds_batch\n",
    "    ids += ids_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "2976b7db211a240125abd5a19c03ddc00865a790"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485b548a7ee70df49fe7cab6d7062fb8d8f172aa</td>\n",
       "      <td>0.008570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a13be637bd66856953494747e1a56e11e394acc</td>\n",
       "      <td>0.597065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d19c0a74340c60c31b677a0032e710886645bc6</td>\n",
       "      <td>0.640729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f45110c8ce329fc4292c2dfb93f1bc73b31d0919</td>\n",
       "      <td>0.999136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e07ddd315e3037431689b18b3631c756a7220102</td>\n",
       "      <td>0.002818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id     label\n",
       "0  485b548a7ee70df49fe7cab6d7062fb8d8f172aa  0.008570\n",
       "1  0a13be637bd66856953494747e1a56e11e394acc  0.597065\n",
       "2  1d19c0a74340c60c31b677a0032e710886645bc6  0.640729\n",
       "3  f45110c8ce329fc4292c2dfb93f1bc73b31d0919  0.999136\n",
       "4  e07ddd315e3037431689b18b3631c756a7220102  0.002818"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'id':ids, 'label':preds})\n",
    "df.to_csv(\"baseline_nasnet.csv\", index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
